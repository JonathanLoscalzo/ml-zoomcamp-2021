{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mnl35-NT4Vx"
      },
      "source": [
        "## Homework\n",
        "\n",
        "### Dataset\n",
        "\n",
        "In this homework, we'll build a model for predicting if we have an image of a dog or a cat. For this,\n",
        "we will use the \"Dogs & Cats\" dataset that can be downloaded from [Kaggle](https://www.kaggle.com/c/dogs-vs-cats/data). \n",
        "\n",
        "You need to download the `train.zip` file.\n",
        "\n",
        "If you have troubles downloading from Kaggle, use [this link](https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip) instead:\n",
        "\n",
        "```bash\n",
        "wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
        "```\n",
        "\n",
        "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch. \n",
        "\n",
        "**Note:** You don't need a computer with a GPU for this homework. A laptop or any personal computer should be sufficient. \n",
        "\n",
        "\n",
        "### Data Preparation\n",
        "\n",
        "The dataset contains 12,500 images of cats and 12,500 images of dogs. \n",
        "\n",
        "Now we need to split this data into train and validation\n",
        "\n",
        "* Create a `train` and `validation` folders\n",
        "* In each folder, create `cats` and `dogs` folders\n",
        "* Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs - and put them in respective folders\n",
        "* Move the remaining 2,500 images to the validation folder (from 10000 to 12499)\n",
        "\n",
        "You can do this manually or with Python (check `os` and `shutil` packages).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I5zz6vVCZ90"
      },
      "source": [
        "!rm -R train\n",
        "!rm -R validation"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdUiMHm_TyoX"
      },
      "source": [
        "import os \n",
        "import shutil\n",
        "\n",
        "if not os.path.exists('./train.zip'):\n",
        "  !wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
        "  !unzip train.zip\n",
        "\n",
        "CONTENT_DIR = './'\n",
        "TRAIN_DIR = CONTENT_DIR + 'train'\n",
        "VALID_DIR = CONTENT_DIR + 'validation'\n",
        "\n",
        "# Extract dataset\n",
        "import zipfile\n",
        "with zipfile.ZipFile(CONTENT_DIR + 'train.zip', 'r') as zipf:\n",
        "    zipf.extractall('data')\n",
        "\n",
        "\n",
        "# split at train and validation folders\n",
        "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
        "os.makedirs(VALID_DIR, exist_ok=True)\n",
        "\n",
        "# Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs - and put them in respective folders\n",
        "files = os.listdir(CONTENT_DIR+'data/train')\n",
        "\n",
        "for file in files[0:10000]:\n",
        "  shutil.copy(os.path.join(CONTENT_DIR+'data/train', file), TRAIN_DIR)\n",
        "\n",
        "for file in files[10000:12500]:\n",
        "  shutil.copy(os.path.join(CONTENT_DIR+'data/train', file), VALID_DIR)\n",
        "\n",
        "\n",
        "for folder in [TRAIN_DIR, VALID_DIR]:\n",
        "  files = os.listdir(folder)\n",
        "  dog_filenames = [fn for fn in files if fn.startswith('dog')]\n",
        "  cat_filenames = [fn for fn in files if fn.startswith('cat')]\n",
        "  make_dirs = [folder + a for a in ['/dog', '/cat']]\n",
        "  \n",
        "  for dir, filenames in zip(make_dirs, [dog_filenames, cat_filenames]):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "    for animal in filenames:\n",
        "      if os.path.isfile(folder+\"/\"+animal):\n",
        "        shutil.move(folder+\"/\"+animal, dir)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb_-F7FZUIUZ"
      },
      "source": [
        "### Model\n",
        "\n",
        "For this homework we will use Convolutional Neural Network (CNN. Like in the lectures, we'll use Keras.\n",
        "\n",
        "You need to develop the model with following structure:\n",
        "\n",
        "* The shape for input should be `(150, 150, 3)`\n",
        "* Next, create a covolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
        "    * Use 32 filters\n",
        "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
        "    * Use `'relu'` as activation \n",
        "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
        "    * Set the pooling size to `(2, 2)`\n",
        "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
        "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
        "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
        "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
        "\n",
        "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
        "\n",
        "* `SGD(lr=0.002, momentum=0.8)`\n",
        "\n",
        "\n",
        "For clarification about kernel size and max pooling, check [Week #11 Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DOcTwl6hdQun",
        "outputId": "930bab06-80f7-43b6-a38a-0a9a3710c3da"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4pXJUlKT_xh"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers  as layers\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "INPUT_SHAPE=(150,150)\n",
        "\n",
        "class CNN():\n",
        "  model : keras.Model = None\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    inputs = keras.Input(shape=(*input_shape, 3), name=\"img\")\n",
        "    \n",
        "    # backbone\n",
        "    x = layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(units=64, activation='relu')(x)\n",
        "    \n",
        "    # detector\n",
        "    outputs = layers.Dense(units=1, activation='sigmoid')(x)\n",
        "    self.model = keras.Model(inputs, outputs)\n",
        "\n",
        "    self.optimizer = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
        "    self.loss = keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    self.model.compile(\n",
        "        optimizer=self.optimizer, \n",
        "        loss=self.loss,\n",
        "        metrics=[\"accuracy\"])\n",
        "\n",
        "    return self.model\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm4EnzlJcXJ9"
      },
      "source": [
        "network = CNN()\n",
        "model = network.build(input_shape = INPUT_SHAPE)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NISYdAegWaN2",
        "outputId": "837dbe68-a922-4f9c-b755-48d56f7ae735"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_data = np.random.rand(1, 150, 150, 3)\n",
        "input_data.shape\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF1W6dycWgCW",
        "outputId": "c3f77fc6-9d2d-4aff-9f3b-2647efdad7c3"
      },
      "source": [
        "model.predict(input_data)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.47437868]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekV2BQsZe0Fu"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "Since we have a binary classification problem, what is the best loss function for us?\n",
        "\n",
        "Note: since we specify an activation for the output layer, we don't need to set `from_logits=True`\n",
        "\n",
        "\n",
        "#### Answer 1) \n",
        "\n",
        "We might use keras.losses.BinaryCrossentropy(from_logits=False) with activation='sigmoid' at last layer. \n",
        "Other approaches: use SparseCategoricalCrossentropy or CategoricalCrossentropy  but changing the transforming `y` in one-hot encoding\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqKmrTalgHqT"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "What's the total number of parameters of the model? You can use the `summary` method for that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp87b4gEceWt",
        "outputId": "6096660e-ca23-4b34-802e-646af0c2bd09"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " img (InputLayer)            [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 175232)            0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                11214912  \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,215,873\n",
            "Trainable params: 11,215,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3LCCU3tgPdX"
      },
      "source": [
        "### Generators and Training\n",
        "\n",
        "For the next two questions, use the following data generator for both train and validation:\n",
        "\n",
        "```python\n",
        "ImageDataGenerator(rescale=1./255)\n",
        "```\n",
        "\n",
        "* We don't need to do any additional pre-processing for the images.\n",
        "* When reading the data from train/val directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
        "* Use `batch_size=20`\n",
        "* Use `shuffle=True` for both training and validaition \n",
        "\n",
        "For training use `.fit()` with the following params:\n",
        "\n",
        "```python\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")\n",
        "```\n",
        "\n",
        "Note `validation_steps=50` - this parameter says \"run only 50 steps on the validation data for evaluating the results\". \n",
        "This way we iterate a bit faster, but don't use the entire validation dataset.\n",
        "That's why it's important to shuffle the validation dataset as well. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S1iN0RKgZQQ",
        "outputId": "53b57154-3b42-4bfd-e43a-fa62834e3e48"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "train_ds = train_gen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=INPUT_SHAPE,\n",
        "    batch_size=20,\n",
        "    shuffle=True,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_gen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "val_ds = val_gen.flow_from_directory(\n",
        "    VALID_DIR,\n",
        "    target_size=INPUT_SHAPE,\n",
        "    batch_size=20,\n",
        "    shuffle=True,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQQJyruGgXtW"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "What is the median of training accuracy for this model?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG4ByQnfgJeb",
        "outputId": "80eef620-c319-4cea-c185-dbadbb348cd0"
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 11s 103ms/step - loss: 0.6971 - accuracy: 0.5060 - val_loss: 0.6911 - val_accuracy: 0.5600\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.6896 - accuracy: 0.5450 - val_loss: 0.6880 - val_accuracy: 0.5350\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.6846 - accuracy: 0.5700 - val_loss: 0.6850 - val_accuracy: 0.5560\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.6788 - accuracy: 0.5665 - val_loss: 0.6785 - val_accuracy: 0.5790\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6768 - accuracy: 0.5660 - val_loss: 0.6728 - val_accuracy: 0.6170\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6761 - accuracy: 0.5775 - val_loss: 0.6639 - val_accuracy: 0.5980\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.6651 - accuracy: 0.5940 - val_loss: 0.6690 - val_accuracy: 0.5820\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.6562 - accuracy: 0.6135 - val_loss: 0.6682 - val_accuracy: 0.5730\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.6516 - accuracy: 0.6190 - val_loss: 0.6793 - val_accuracy: 0.5610\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.6569 - accuracy: 0.5915 - val_loss: 0.6665 - val_accuracy: 0.6050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh0bqfbFCvvH",
        "outputId": "b29b3090-6011-4570-a2e4-0a9ae714732e"
      },
      "source": [
        "np.mean(history.history['accuracy'])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5748999953269959"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whSSQ8KCFTyz"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "What is the standard deviation of training loss for this model?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2fJxVrDFUfB",
        "outputId": "c9ae1ba4-91dd-4b78-8b50-16e3bbb9b899"
      },
      "source": [
        "np.std(history.history['loss'])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.014525656717254233"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL2V3PURFjPF"
      },
      "source": [
        "### Data Augmentation\n",
        "\n",
        "For the next two questions, we'll generate more data using data augmentations. \n",
        "\n",
        "Add the following augmentations to your training data generator:\n",
        "\n",
        "* `rotation_range=40,`\n",
        "* `width_shift_range=0.2,`\n",
        "* `height_shift_range=0.2,`\n",
        "* `shear_range=0.2,`\n",
        "* `zoom_range=0.2,`\n",
        "* `horizontal_flip=True,`\n",
        "* `fill_mode='nearest'`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kguI9P2KgHP",
        "outputId": "5f90a2e8-bf45-44ef-8a34-d4167df0a24e"
      },
      "source": [
        "train_gen = ImageDataGenerator(\n",
        "  rescale=1./255,\n",
        "  rotation_range=40,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_ds = train_gen.flow_from_directory(\n",
        "  TRAIN_DIR,\n",
        "  target_size=INPUT_SHAPE,\n",
        "  batch_size=20,\n",
        "  shuffle=True,\n",
        "  class_mode='binary'\n",
        ")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvsFzVMzFk6b"
      },
      "source": [
        "\n",
        "### Question 5 \n",
        "\n",
        "Let's train our model for 10 more epochs using the same code as previously.\n",
        "Make sure you don't re-create the model - we want to continue training the model\n",
        "we already started training.\n",
        "\n",
        "What is the mean of validation loss for the model trained with augmentations?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HocLi5gQK0IJ",
        "outputId": "4d5ae16f-926b-47ad-c650-3079b6b7718e"
      },
      "source": [
        "history_2 = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 20s 199ms/step - loss: 0.6729 - accuracy: 0.5835 - val_loss: 0.6562 - val_accuracy: 0.5930\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.6749 - accuracy: 0.5750 - val_loss: 0.6642 - val_accuracy: 0.5920\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.6691 - accuracy: 0.5785 - val_loss: 0.6509 - val_accuracy: 0.6270\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.6688 - accuracy: 0.5860 - val_loss: 0.6420 - val_accuracy: 0.6170\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.6601 - accuracy: 0.5945 - val_loss: 0.6617 - val_accuracy: 0.5620\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.6632 - accuracy: 0.5865 - val_loss: 0.6496 - val_accuracy: 0.6170\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.6575 - accuracy: 0.6005 - val_loss: 0.6356 - val_accuracy: 0.6220\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.6522 - accuracy: 0.5990 - val_loss: 0.6331 - val_accuracy: 0.6070\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6567 - accuracy: 0.6015 - val_loss: 0.6328 - val_accuracy: 0.6110\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.6529 - accuracy: 0.6185 - val_loss: 0.6478 - val_accuracy: 0.6120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq-jhNRNK51S",
        "outputId": "194c9a79-9d24-4d7d-b80c-60e3fbc1c16e"
      },
      "source": [
        "np.mean(history_2.history['val_loss'])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6473888695240021"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qrFabcEFmMQ"
      },
      "source": [
        "\n",
        "### Question 6\n",
        "\n",
        "What's the average of validation accuracy for the last 5 epochs (from 6 to 10)\n",
        "for the model trained with augmentations?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALWFVc44FWIg",
        "outputId": "7ea99c84-d3c5-45a1-af3c-643c60f76a9d"
      },
      "source": [
        "np.mean(history_2.history['val_accuracy'][-5:])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6137999892234802"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2lpYAoxLxAR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}